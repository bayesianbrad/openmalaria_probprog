{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mWarning: Empirical distributions on disk may perform slow because GNU DBM is not available. Please install and configure gdbm library for Python for better speed.\u001b[0m\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'to_variable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c3cb04d94c1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyprob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInferenceEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUniform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoisson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'to_variable'"
     ]
    }
   ],
   "source": [
    "import pyprob\n",
    "import itertools\n",
    "from pyprob import Model, InferenceEngine\n",
    "from pyprob.distributions import Uniform, Normal, Categorical, Poisson\n",
    "from pyprob.util import to_variable, to_numpy\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "colors = [cm.inferno(x) for x in np.linspace(0, 1, 5)]\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will have to be modfied accordingly\n",
    "min_energy_deposit = 0.05  # caloutils::minEnergyDeposit in sharpa_tau_decay.cpp\n",
    "\n",
    "def particle_name(pid):\n",
    "    if abs(pid) > pid:\n",
    "        return 'anti-' + pypdt.get(abs(pid)).name\n",
    "    else:\n",
    "        return pypdt.get(pid).name\n",
    "\n",
    "def plot_distribution(dist, plot_samples=2000, title='', ground_truth_trace=None, file_name=None, infer_observation_importance=1.):\n",
    "    if dist.length > 0:\n",
    "        #[ground_truth_trace.result[3], ground_truth_trace.result[0], ground_truth_trace.result[1], ground_truth_trace.result[2]]\n",
    "        dist_resampled = dist.resample(plot_samples)\n",
    "        dist_px = dist_resampled.map(lambda x: float(x[0]))\n",
    "        dist_py = dist_resampled.map(lambda x: float(x[1]))\n",
    "        dist_pz = dist_resampled.map(lambda x: float(x[2]))\n",
    "        dist_channel = dist_resampled.map(lambda x: int(x[3]))\n",
    "        dist_final_state_particles = dist_resampled.map(lambda x: x[4:4+(30*8)].view(-1,8))\n",
    "        dist_final_state_particles_px = dist_final_state_particles.map(lambda x: x[:, 0])\n",
    "        dist_final_state_particles_py = dist_final_state_particles.map(lambda x: x[:, 1])\n",
    "        dist_final_state_particles_pz = dist_final_state_particles.map(lambda x: x[:, 2])\n",
    "        dist_final_state_particles_E = dist_final_state_particles.map(lambda x: x[:, 3])\n",
    "        dist_final_state_particles_theta = dist_final_state_particles.map(lambda x: x[:, 4])\n",
    "        dist_final_state_particles_phi = dist_final_state_particles.map(lambda x: x[:, 5])\n",
    "        dist_final_state_particles_id = dist_final_state_particles.map(lambda x: x[:, 6])\n",
    "        dist_final_state_particles_calo_visible = dist_final_state_particles.map(lambda x: x[:, 7])\n",
    "\n",
    "        dist_px_samples = dist_px.values\n",
    "        dist_py_samples = dist_py.values\n",
    "        dist_pz_samples = dist_pz.values\n",
    "        dist_channel_samples = dist_channel.values\n",
    "        dist_final_state_particles_px_samples = dist_final_state_particles_px.values\n",
    "        dist_final_state_particles_py_samples = dist_final_state_particles_py.values\n",
    "        dist_final_state_particles_pz_samples = dist_final_state_particles_pz.values\n",
    "        dist_final_state_particles_E_samples = dist_final_state_particles_E.values\n",
    "        dist_final_state_particles_theta_samples = dist_final_state_particles_theta.values\n",
    "        dist_final_state_particles_phi_samples = dist_final_state_particles_phi.values\n",
    "        dist_final_state_particles_id_samples = dist_final_state_particles_id.values\n",
    "        dist_final_state_particles_calo_visible_samples = dist_final_state_particles_calo_visible.values\n",
    "\n",
    "        final_state_particles_pid_flattened = []\n",
    "        final_state_particles_calo_visible_flattened = []\n",
    "        final_state_particles_px_flattened_samples = []\n",
    "        final_state_particles_py_flattened_samples = []\n",
    "        final_state_particles_pz_flattened_samples = []\n",
    "        final_state_particles_E_flattened_samples = []\n",
    "        final_state_particles_theta_flattened_samples = []\n",
    "        final_state_particles_phi_flattened_samples = []\n",
    "        for i in range(dist_resampled.length):\n",
    "            for j in range(30):\n",
    "                pid = dist_final_state_particles_id_samples[i][j]\n",
    "                if float(pid) > -99999:\n",
    "                    final_state_particles_pid_flattened.append(pid)\n",
    "                    final_state_particles_calo_visible_flattened.append(float(dist_final_state_particles_calo_visible_samples[i][j]))\n",
    "                    final_state_particles_px_flattened_samples.append(float(dist_final_state_particles_px_samples[i][j]))\n",
    "                    final_state_particles_py_flattened_samples.append(float(dist_final_state_particles_py_samples[i][j]))\n",
    "                    final_state_particles_pz_flattened_samples.append(float(dist_final_state_particles_pz_samples[i][j]))\n",
    "                    final_state_particles_E_flattened_samples.append(float(dist_final_state_particles_E_samples[i][j]))\n",
    "                    final_state_particles_theta_flattened_samples.append(float(dist_final_state_particles_theta_samples[i][j]))\n",
    "                    final_state_particles_phi_flattened_samples.append(float(dist_final_state_particles_phi_samples[i][j]))\n",
    "\n",
    "        dist_channel_flattened = pyprob.distributions.Empirical(dist_channel_samples, combine_duplicates=True)\n",
    "        dist_channel_flattened_values = dist_channel_flattened.values\n",
    "        dist_channel_flattened_weights = [float(w) for w in dist_channel_flattened.weights]\n",
    "        dist_channel_str = 'Channel probabilities: ' + ', '.join(['{}: {:.3f}'.format(v, w) for v, w in zip(dist_channel_flattened_values, dist_channel_flattened_weights)])\n",
    "\n",
    "        dist_final_state_particles_id_flattened = pyprob.distributions.Empirical(final_state_particles_pid_flattened, combine_duplicates=True).map(lambda x: particle_name(int(x)))\n",
    "        dist_final_state_particles_id_flattened_values = dist_final_state_particles_id_flattened.values\n",
    "        dist_final_state_particles_id_flattened_weights = [float(w) for w in dist_final_state_particles_id_flattened.weights]\n",
    "        dist_final_state_particles_id_flattened_str = 'Final state particle probabilities: ' + ', '.join(['{}: {:.3f}'.format(v, w) for v, w in zip(dist_final_state_particles_id_flattened_values, dist_final_state_particles_id_flattened_weights)])\n",
    "\n",
    "        dist_final_state_particles_calo_visible_flattened = pyprob.distributions.Empirical(final_state_particles_calo_visible_flattened, combine_duplicates=True).map(lambda x: 'Yes' if int(x) == 1 else 'No')\n",
    "        dist_final_state_particles_calo_visible_flattened_values = dist_final_state_particles_calo_visible_flattened.values\n",
    "        dist_final_state_particles_calo_visible_flattened_weights = [float(w) for w in dist_final_state_particles_calo_visible_flattened.weights]\n",
    "\n",
    "        fig = plt.figure(figsize=(30, 15))\n",
    "        gs1 = gridspec.GridSpec(3, 5, width_ratios=[2,1,1,1,1], wspace=0.2, hspace=0.4)\n",
    "        gs2 = gridspec.GridSpec(3, 5, width_ratios=[2.4,1,1,1,1], wspace=0.2, hspace=0.4)\n",
    "        ax1 = fig.add_subplot(gs1[0], projection='3d')\n",
    "        ax2 = fig.add_subplot(gs2[1])\n",
    "        ax3 = fig.add_subplot(gs2[2])\n",
    "        ax4 = fig.add_subplot(gs2[3])\n",
    "        ax5 = fig.add_subplot(gs2[4])\n",
    "        ax6 = fig.add_subplot(gs1[5], projection='3d')\n",
    "        ax7 = fig.add_subplot(gs2[6])\n",
    "        ax8 = fig.add_subplot(gs2[7])\n",
    "        ax9 = fig.add_subplot(gs2[8])\n",
    "        ax10 = fig.add_subplot(gs2[9])\n",
    "        ax11 = fig.add_subplot(gs1[10], projection='3d')\n",
    "        ax12 = fig.add_subplot(gs2[11])\n",
    "        ax13 = fig.add_subplot(gs2[12])\n",
    "        ax14 = fig.add_subplot(gs2[13])\n",
    "        ax15 = fig.add_subplot(gs2[14])\n",
    "        ax2.text(0, 1.5, title)\n",
    "        ax2.text(0, 1.4, dist_channel_str)\n",
    "        ax2.text(0, 1.3, dist_final_state_particles_id_flattened_str)\n",
    "\n",
    "        ax2.title.set_text('Channel')\n",
    "        # ax2.text(0.5, 0.5, 'mean={:.3f} (solid), stddev={:.3f}'.format(float(dist_channel.mean), float(dist_channel.stddev)), ha='center', va='center', transform=ax2.transAxes)\n",
    "        ax3.title.set_text('p_x')\n",
    "        ax3.text(0.5, 0.5, 'mean={:.3f} (solid), stddev={:.3f}'.format(float(dist_px.mean), float(dist_px.stddev)), ha='center', va='center', transform=ax3.transAxes)\n",
    "        ax4.title.set_text('p_y')\n",
    "        ax4.text(0.5, 0.5, 'mean={:.3f} (solid), stddev={:.3f}'.format(float(dist_py.mean), float(dist_py.stddev)), ha='center', va='center', transform=ax4.transAxes)\n",
    "        ax5.title.set_text('p_z')\n",
    "        ax5.text(0.5, 0.5, 'mean={:.3f} (solid), stddev={:.3f}'.format(float(dist_pz.mean), float(dist_pz.stddev)), ha='center', va='center', transform=ax5.transAxes)\n",
    "\n",
    "        _ = ax2.hist(dist_channel_samples, bins=np.arange(-0.5,38+0.5,1), density=True, alpha=0.6, color=colors_inferno[0])\n",
    "        ax2.set_xlim([-1,39])\n",
    "        ax2.set_ylim([0,1])\n",
    "        # ax2.axvline(float(dist_channel.mean), color='gray', linestyle='solid', linewidth=1)\n",
    "        ax2.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "        _ = ax3.hist(dist_px_samples, bins=np.arange(-2.5,2.5+0.1,0.1), density=True, alpha=0.6, color=colors_inferno[1])\n",
    "        ax3.set_xlim([-2.5,2.5])\n",
    "        ax3.set_ylim([0,10])\n",
    "        ax3.axvline(float(dist_px.mean), color='gray', linestyle='solid', linewidth=1)\n",
    "        _ = ax4.hist(dist_py_samples, bins=np.arange(-2.5,2.5+0.1,0.1), density=True, alpha=0.6, color=colors_inferno[2])\n",
    "        ax4.set_xlim([-2.5,2.5])\n",
    "        ax4.set_ylim([0,10])\n",
    "        ax4.axvline(float(dist_py.mean), color='gray', linestyle='solid', linewidth=1)\n",
    "        _ = ax5.hist(dist_pz_samples, bins=np.arange(43,47+0.08,0.08), density=True, alpha=0.6, color=colors_inferno[3])\n",
    "        ax5.set_xlim([43,47])\n",
    "        ax5.set_ylim([0,12.5])\n",
    "        ax5.axvline(float(dist_pz.mean), color='gray', linestyle='solid', linewidth=1)\n",
    "\n",
    "        dist_calo = dist.resample(int(plot_samples/4)).map(lambda x: x[4+(30*8):])\n",
    "        calo_simulated = dist_calo.mean.view(35,35,20).data.numpy()\n",
    "        calo_simulated_flat = calo_simulated.reshape(-1)\n",
    "        ax6.title.set_text('Simulated calorimeter mean')\n",
    "        ax6.set_xlabel('x')\n",
    "        ax6.set_ylabel('y')\n",
    "        ax6.set_zlabel('z')\n",
    "        ax6.set_aspect('equal')\n",
    "        cmbr = mpl.colors.LinearSegmentedColormap.from_list('blue_to_red',['b','r'])\n",
    "        cnorm = mpl.colors.Normalize(vmin=calo_simulated_flat.min(),vmax=calo_simulated_flat.max())\n",
    "        cpick = mpl.cm.ScalarMappable(norm=cnorm,cmap=cmbr)\n",
    "        cpick.set_array([])\n",
    "        if calo_simulated_flat.max() - calo_simulated_flat.min() > 0:\n",
    "            ix,iy,iz = np.mgrid[-3:3:35j,-3:3:35j,4:15:20j]\n",
    "            calo_simulated_flat_normalized = np.clip((calo_simulated_flat - calo_simulated_flat.min())/(calo_simulated_flat.max() - calo_simulated_flat.min()), 0, 1)\n",
    "            colors = [[x,0,1-x,x] for x in calo_simulated_flat_normalized]\n",
    "            ax6.scatter(ix, iy, iz, s=100, c=colors, marker='o', edgecolor='none')\n",
    "            plt.colorbar(cpick, ax=ax6, fraction=0.02)\n",
    "\n",
    "        # dist_final_state_particles_all_px = []\n",
    "        # dist_final_state_particles_all_py = []\n",
    "        # dist_final_state_particles_all_pz = []\n",
    "        # for i in range(dist_final_state_particles.length):\n",
    "        #     px = dist_final_state_particles_px_samples[i]\n",
    "        #     py = dist_final_state_particles_py_samples[i]\n",
    "        #     pz = dist_final_state_particles_pz_samples[i]\n",
    "        #     dist_final_state_particles_all_px.append(px[px>-99999].data.cpu().numpy())\n",
    "        #     dist_final_state_particles_all_py.append(py[py>-99999].data.cpu().numpy())\n",
    "        #     dist_final_state_particles_all_pz.append(pz[pz>-99999].data.cpu().numpy())\n",
    "        _ = ax8.hist(final_state_particles_px_flattened_samples, bins=40, histtype='bar', density=True, alpha=0.6, color=colors_inferno[1])\n",
    "        ax8.title.set_text('Final state particles p_x')\n",
    "        _ = ax9.hist(final_state_particles_py_flattened_samples, bins=40, histtype='bar', density=True, alpha=0.6, color=colors_inferno[2])\n",
    "        ax9.title.set_text('Final state particles p_y')\n",
    "        _ = ax10.hist(final_state_particles_pz_flattened_samples, bins=40, histtype='bar', density=True, alpha=0.6, color=colors_inferno[3])\n",
    "        ax10.title.set_text('Final state particles p_z')\n",
    "\n",
    "        ax7.title.set_text('Final state particles')\n",
    "        ax7.bar(range(len(dist_final_state_particles_id_flattened_weights)), dist_final_state_particles_id_flattened_weights, align='center', alpha=0.6, color=colors_inferno[0])\n",
    "        # for tick in ax7.get_xticklabels():\n",
    "            # tick.set_rotation(45)\n",
    "        # xticks = ax7.get_xticklabels()\n",
    "        ax7.set_xticks(range(len(dist_final_state_particles_id_flattened_values)))\n",
    "        ax7.set_xticklabels(dist_final_state_particles_id_flattened_values, rotation=45, ha='right')\n",
    "\n",
    "        ax12.title.set_text('Final state particles calorimeter visible')\n",
    "        ax12.bar(range(len(dist_final_state_particles_calo_visible_flattened_weights)), dist_final_state_particles_calo_visible_flattened_weights, tick_label=dist_final_state_particles_calo_visible_flattened_values, align='center', alpha=0.6, color=colors_inferno[0])\n",
    "\n",
    "        ax13.title.set_text('Final state particles E')\n",
    "        ax13.hist(final_state_particles_E_flattened_samples, bins=40, histtype='bar', density=True, alpha=0.6, color=colors_inferno[0])\n",
    "\n",
    "        ax14.title.set_text('Final state particles theta')\n",
    "        ax14.hist(final_state_particles_theta_flattened_samples, bins=40, histtype='bar', density=True, alpha=0.6, color=colors_inferno[0])\n",
    "\n",
    "        ax15.title.set_text('Final state particles phi')\n",
    "        ax15.hist(final_state_particles_phi_flattened_samples, bins=40, histtype='bar', density=True, alpha=0.6, color=colors_inferno[0])\n",
    "\n",
    "\n",
    "        if ground_truth_trace is not None:\n",
    "            calo_observed = ground_truth_trace.samples_observed[0].distribution.mean.view(35,35,20).data.numpy()\n",
    "            calo_observed_flat = calo_observed.reshape(-1)\n",
    "            ax1.title.set_text('Observed calorimeter')\n",
    "            ax1.set_xlabel('x')\n",
    "            ax1.set_ylabel('y')\n",
    "            ax1.set_zlabel('z')\n",
    "            ax1.set_aspect('equal')\n",
    "            cmbr = mpl.colors.LinearSegmentedColormap.from_list('blue_to_red',['b','r'])\n",
    "            cnorm = mpl.colors.Normalize(vmin=calo_observed_flat.min(),vmax=calo_observed_flat.max())\n",
    "            cpick = mpl.cm.ScalarMappable(norm=cnorm,cmap=cmbr)\n",
    "            cpick.set_array([])\n",
    "            if calo_observed_flat.max() - calo_observed_flat.min() > 0:\n",
    "                ix,iy,iz = np.mgrid[-3:3:35j,-3:3:35j,4:15:20j]\n",
    "                calo_observed_flat_normalized = np.clip((calo_observed_flat - calo_observed_flat.min())/(calo_observed_flat.max() - calo_observed_flat.min()), 0, 1)\n",
    "                colors = [[x,0,1-x,x] for x in calo_observed_flat_normalized]\n",
    "                ax1.scatter(ix, iy, iz, s=100, c=colors, marker='o', edgecolor='none')\n",
    "                plt.colorbar(cpick, ax=ax1, fraction=0.02)\n",
    "\n",
    "            calo_observed_likelihood_flat = infer_observation_importance * ((np.log(calo_simulated_flat) * calo_observed_flat) - calo_simulated_flat - to_numpy(to_variable(calo_observed_flat + 1).lgamma()))\n",
    "            ax11.title.set_text('Log-likelihood of observed calorimeter')\n",
    "            ax11.set_xlabel('x')\n",
    "            ax11.set_ylabel('y')\n",
    "            ax11.set_zlabel('z')\n",
    "            ax11.set_aspect('equal')\n",
    "            cmbr = mpl.colors.LinearSegmentedColormap.from_list('blue_to_red',['b','r'])\n",
    "            cnorm = mpl.colors.Normalize(vmin=calo_observed_likelihood_flat.min(),vmax=calo_observed_likelihood_flat.max())\n",
    "            cpick = mpl.cm.ScalarMappable(norm=cnorm,cmap=cmbr)\n",
    "            cpick.set_array([])\n",
    "            if calo_observed_likelihood_flat.max() - calo_observed_likelihood_flat.min() > 0:\n",
    "                ix,iy,iz = np.mgrid[-3:3:35j,-3:3:35j,4:15:20j]\n",
    "                calo_observed_likelihood_flat_normalized = np.clip((calo_observed_likelihood_flat - calo_observed_likelihood_flat.min())/(calo_observed_likelihood_flat.max() - calo_observed_likelihood_flat.min()), 0, 1)\n",
    "                colors = [[x,0,1-x,1-x] for x in calo_observed_likelihood_flat_normalized]\n",
    "                ax11.scatter(ix, iy, iz, s=100, c=colors, marker='o', edgecolor='none')\n",
    "                plt.colorbar(cpick, ax=ax11, fraction=0.02)\n",
    "\n",
    "            ax2.axvline(float(ground_truth_trace.result[3]), color='gray', linestyle='dashed', linewidth=2)\n",
    "            ax3.axvline(float(ground_truth_trace.result[0]), color='gray', linestyle='dashed', linewidth=2)\n",
    "            ax4.axvline(float(ground_truth_trace.result[1]), color='gray', linestyle='dashed', linewidth=2)\n",
    "            ax5.axvline(float(ground_truth_trace.result[2]), color='gray', linestyle='dashed', linewidth=2)\n",
    "\n",
    "            # ax2.text(0.5, 0.4, 'ground_truth={:.3f} (dashed)'.format(float(ground_truth_trace.result[3])), ha='center', va='center', transform=ax2.transAxes)\n",
    "            ax3.text(0.5, 0.4, 'ground_truth={:.3f} (dashed)'.format(float(ground_truth_trace.result[0])), ha='center', va='center', transform=ax3.transAxes)\n",
    "            ax4.text(0.5, 0.4, 'ground_truth={:.3f} (dashed)'.format(float(ground_truth_trace.result[1])), ha='center', va='center', transform=ax4.transAxes)\n",
    "            ax5.text(0.5, 0.4, 'ground_truth={:.3f} (dashed)'.format(float(ground_truth_trace.result[2])), ha='center', va='center', transform=ax5.transAxes)\n",
    "\n",
    "            ground_truth_final_state_momenta = ground_truth_trace.result[4:4+(30*8)]\n",
    "            ground_truth_final_state_momenta = ground_truth_final_state_momenta[ground_truth_final_state_momenta > -99999].view(-1,8)\n",
    "            for i in range(ground_truth_final_state_momenta.size(0)):\n",
    "                if float(ground_truth_final_state_momenta[i, 0]) > -99999:\n",
    "                    ax8.axvline(float(ground_truth_final_state_momenta[i, 0]), color='gray', linestyle='dashed', linewidth=2)\n",
    "                if float(ground_truth_final_state_momenta[i, 1]) > -99999:\n",
    "                    ax9.axvline(float(ground_truth_final_state_momenta[i, 1]), color='gray', linestyle='dashed', linewidth=2)\n",
    "                if float(ground_truth_final_state_momenta[i, 2]) > -99999:\n",
    "                    ax10.axvline(float(ground_truth_final_state_momenta[i, 2]), color='gray', linestyle='dashed', linewidth=2)\n",
    "                if float(ground_truth_final_state_momenta[i, 3]) > -99999:\n",
    "                    ax13.axvline(float(ground_truth_final_state_momenta[i, 3]), color='gray', linestyle='dashed', linewidth=2)\n",
    "                if float(ground_truth_final_state_momenta[i, 4]) > -99999:\n",
    "                    ax14.axvline(float(ground_truth_final_state_momenta[i, 4]), color='gray', linestyle='dashed', linewidth=2)\n",
    "                if float(ground_truth_final_state_momenta[i, 5]) > -99999:\n",
    "                    ax15.axvline(float(ground_truth_final_state_momenta[i, 5]), color='gray', linestyle='dashed', linewidth=2)\n",
    "\n",
    "        # plt.subplots_adjust(wspace=0.25)\n",
    "        if file_name is not None:\n",
    "            plt.savefig(file_name, bbox_inches='tight')\n",
    "\n",
    "\n",
    "def plot_trace(trace, file_name=None):\n",
    "    data = trace.samples_observed[0].distribution.mean.view(35,35,20).data.numpy()\n",
    "    data_flat = data.reshape(-1)\n",
    "    data_flat_min = min(data_flat) * min_energy_deposit\n",
    "    data_flat_max = max(data_flat) * min_energy_deposit\n",
    "    data_flat_total = np.sum(data_flat) * min_energy_deposit\n",
    "\n",
    "    particles = trace.result[4:4+(30*8)]\n",
    "    particles = particles[particles > -99999].view(-1,8)\n",
    "\n",
    "    trace_text = [str(trace),\n",
    "                  '\\nlatents',\n",
    "                  'p_x      : {}'.format(float(trace.result[0])),\n",
    "                  'p_y      : {}'.format(float(trace.result[1])),\n",
    "                  'p_z      : {}'.format(float(trace.result[2])),\n",
    "                  'channel  : {}'.format(int(trace.result[3])),\n",
    "                  'particles: {}'.format(particles.size(0)),\n",
    "                  str(particles),\n",
    "                  'calorimeter',\n",
    "                  'min   : {:.3f} GeV'.format(data_flat_min),\n",
    "                  'max   : {:.3f} GeV'.format(data_flat_max),\n",
    "                  'total : {:.3f} GeV'.format(data_flat_total)]\n",
    "    trace_text = '\\n'.join(trace_text)\n",
    "#     print(trace_text)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "\n",
    "    ax1.text(0, 0, trace_text)\n",
    "    ax1.axis('off')\n",
    "    cmbr = mpl.colors.LinearSegmentedColormap.from_list('blue_to_red',['b','r'])\n",
    "    cnorm = mpl.colors.Normalize(vmin=data_flat_min,vmax=data_flat_max)\n",
    "    cpick = mpl.cm.ScalarMappable(norm=cnorm,cmap=cmbr)\n",
    "    cpick.set_array([])\n",
    "\n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel('y')\n",
    "    ax2.set_zlabel('z')\n",
    "    ax2.set_aspect('equal')\n",
    "\n",
    "    if data_flat.max() - data_flat.min() > 0:\n",
    "        ix,iy,iz = np.mgrid[-3:3:35j,-3:3:35j,4:15:20j]\n",
    "        data_flat_normalized = np.clip((data_flat - data_flat.min())/(data_flat.max() - data_flat.min()), 0, 1)\n",
    "        colors = [[x,0,1-x,x] for x in data_flat_normalized]\n",
    "        ax2.scatter(ix, iy, iz, s=100, c=colors, marker='o', edgecolor='none')\n",
    "\n",
    "        plt.colorbar(cpick,label='Deposited energy (GeV)',fraction=0.02)\n",
    "\n",
    "    if file_name is not None:\n",
    "        plt.savefig(file_name, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the prior\n",
    "We construct an empirical distribution of the prior, using a given number of traces. Beware, large number of traces can take a long time. traces=500 gives a reasonable-looking plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyprob.RemoteModel('tcp://localhost:2345') # replace accordingly\n",
    "prior_dist = model.prior_distribution(num_traces=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate (marginalize) the distribution into distributions over momenta and channel, by mapping a function. (Physics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prior_dist_px = prior_dist.map(lambda x: float(x[0]))\n",
    "prior_dist_py = prior_dist.map(lambda x: float(x[1]))\n",
    "prior_dist_pz = prior_dist.map(lambda x: float(x[2]))\n",
    "prior_dist_channel = prior_dist.map(lambda x: int(x[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can compute expectations under any distribution (prior or posterior):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prior_dist_pz.expectation(lambda x: math.sin(x)/x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can also sample from these distributions, and inspect values and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prior_dist_pz.sample()\n",
    "prior_dist_channel.values\n",
    "prior_dist_channel.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(prior_dist, title='Prior distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute the model, inspect resulting traces and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = next(model._trace_generator())\n",
    "plot_trace(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infer(ground_truth_trace, num_traces=10, inference_engine=InferenceEngine.IMPORTANCE_SAMPLING):\n",
    "    observation = ground_truth_trace.samples_observed[0].distribution.mean * min_energy_deposit\n",
    "    posterior = model.posterior_distribution(num_traces, inference_engine, observation=observation)\n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Inference with Metropolis Hastings\n",
    "\n",
    "We run inference with single-site Metropolis Hastings.\n",
    "\n",
    "First we generate a trace to give us ground truth latents and corresponding calorimeter output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_trace = next(model._trace_generator())\n",
    "plot_trace(ground_truth_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run inference in the model, conditioning on the calorimeter output from ground_truth_trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_metropolis_hastings = infer(ground_truth_trace,100, inference_engine=InferenceEngine.LIGHTWEIGHT_METROPOLIS_HASTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(posterior_metropolis_hastings, title=posterior_metropolis_hastings.name, ground_truth_trace=ground_truth_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train inference network\n",
    "\n",
    "# pyprob.set_cuda(True)\n",
    "# model._inference_network = None\n",
    "model.learn_inference_network(num_traces=20, observe_embedding=pyprob.nn.ObserveEmbedding.CONVNET_3D_4C, observe_reshape=[1,35,35,20], batch_size=4, valid_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Run inference using proposals from the trained inference network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_inference_compilation = infer(ground_truth_trace, 10, inference_engine=InferenceEngine.IMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_distribution(posterior_inference_compilation, title=posterior_inference_compilation.name, ground_truth_trace=ground_truth_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ":\n",
    "plot_distribution(posterior_inference_compilation.unweighted(), title=posterior_inference_compilation.name, ground_truth_trace=ground_truth_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
